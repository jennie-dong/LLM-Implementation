{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\") # 124M\n",
    "sd_hf = model_hf.state_dict()\n",
    "\n",
    "for k, v in sd_hf.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_hf[\"transformer.wpe.weight\"].view(-1)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(sd_hf[\"transformer.wpe.weight\"], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 150])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 200])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sd_hf[\"transformer.h.1.attn.c_attn.weight\"][:300,:300], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们手动实现文本生成的采样逻辑,通过 PyTorch 进行推理，不依赖 Hugging Face 的 pipeline\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# 加载预训练的 GPT-2 模型\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")  # 124M\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "\n",
    "# 设置随机种子，确保采样结果可复现\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# 初始输入 token 序列\n",
    "tokens = [15496, 11, 314, 1101, 257, 3303, 2746, 11]  # 对应编码后的 token\n",
    "tokens = torch.tensor(tokens, dtype=torch.long)  # 转为张量，形状为 (8,)\n",
    "tokens = tokens.unsqueeze(0).repeat(5, 1)  # 扩展为 (5, 8)，表示生成 5 个样本\n",
    "x = tokens.to('cuda')  # 送入 GPU\n",
    "\n",
    "# 开始生成！\n",
    "while x.size(1) < 30:  # 最长生成长度为 30\n",
    "    # 前向传播，获取 logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)[0]  # 输出形状为 (B, T, vocab_size)\n",
    "        logits = logits[:, -1, :]  # 只取最后一个位置的 logits，形状为 (B, vocab_size)\n",
    "        probs = F.softmax(logits, dim=-1)  # 转为概率分布\n",
    "        # 执行 top-k 采样，k=50（和 Hugging Face 默认一致）\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)  # (B, 50)\n",
    "        # 从 top-k 中按概率采样一个 token\n",
    "        # 注意 multinomial 不要求输入概率之和为 1\n",
    "        ix = torch.multinomial(topk_probs, 1)  # (B, 1)\n",
    "        # 根据采样结果取出对应的 token 索引\n",
    "        xcol = torch.gather(topk_indices, -1, ix)  # (B, 1)\n",
    "        # 将新 token 拼接到输入序列后面\n",
    "        x = torch.cat((x, xcol), dim=1)\n",
    "\n",
    "# 输出生成的文本\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "for i in range(5):\n",
    "    tokens = x[i, :30].tolist()  # 取前 30 个 token\n",
    "    decoded = enc.decode(tokens)  # 解码为字符串\n",
    "    print(\">\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny shakespeare dataset\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "data = text[:1000]\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(data)\n",
    "print(tokens[:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "buf = torch.tensor(tokens[:24 + 1])\n",
    "x = buf[:-1].view(4, 6)\n",
    "y = buf[1:].view(4, 6)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd_hf[\"lm_head.weight\"].shape)\n",
    "print(sd_hf[\"transformer.wte.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sd_hf[\"lm_head.weight\"] == sd_hf[\"transformer.wte.weight\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd_hf[\"lm_head.weight\"].data_ptr())\n",
    "print(sd_hf[\"transformer.wte.weight\"].data_ptr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差流中的标准差会随着层数增加而增长（如果不控制的话）\n",
    "# 这里通过缩放噪声，使其在多层中保持稳定\n",
    "\n",
    "x = torch.zeros(768)  # 初始化一个 768 维的张量（模拟残差流）\n",
    "n = 100  # 比如说 100 层\n",
    "\n",
    "for i in range(n):\n",
    "    # 每层加上一组高斯噪声，并使用 1/sqrt(n) 缩放防止方差爆炸\n",
    "    x += n**-0.5 * torch.randn(768)\n",
    "\n",
    "# 打印最终 x 的标准差\n",
    "print(x.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 一个非常简单的小型多层感知机（MLP）\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(16, 32),  \n",
    "    torch.nn.GELU(),          \n",
    "    torch.nn.Linear(32, 1)   \n",
    ")\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "x = torch.randn(4, 16)\n",
    "y = torch.randn(4, 1)\n",
    "# 将模型参数的梯度清零\n",
    "net.zero_grad()\n",
    "# 前向传播，获得模型输出\n",
    "yhat = net(x)\n",
    "# 计算均方误差损失（MSE），reduction='mean' 表示对所有样本平均\n",
    "loss = torch.nn.functional.mse_loss(yhat, y)\n",
    "# 反向传播，计算所有参数的梯度\n",
    "loss.backward()\n",
    "# 打印第一个线性层的权重梯度（只显示前10个元素）\n",
    "print(net[0].weight.grad.view(-1)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()  # 清空所有梯度\n",
    "for i in range(4):  # 模拟每次处理一个样本（即 B=1）\n",
    "    yhat = net(x[i])  # 前向传播，预测第 i 个样本\n",
    "    loss = torch.nn.functional.mse_loss(yhat, y[i])  # 单样本损失（默认是 scalar）\n",
    "    loss = loss / 4  # 手动除以 4，恢复平均损失的语义\n",
    "    loss.backward()  # 累积梯度\n",
    "# 打印第一个线性层的权重梯度（前10个元素）\n",
    "print(net[0].weight.grad.view(-1)[:10])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
